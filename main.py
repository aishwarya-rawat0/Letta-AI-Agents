from letta import create_client
from letta.schemas.memory import ChatMemory
from letta import EmbeddingConfig, LLMConfig
import logging
from letta.schemas.llm_config import LLMConfig
import os
from letta.prompts import gpt_system
from dotenv import load_dotenv
import os

load_dotenv()
print("OpenAI API Key:", os.getenv("OPENAI_API_KEY"))


# chat = ChatTogether(
#     model="meta-llama/Llama-3-70b-chat-hf",
#     together_api_key = ''
# )

logging.basicConfig(level = logging.INFO)
logger = logging.getLogger()



agent_name = "test3"

client = create_client() 

if client.get_agent_id(agent_name): 
    client.delete_agent(client.get_agent_id(agent_name))
    
    
agent_state = client.create_agent(
    # agents name (unique per user, autogenerated if not provided)
    name= agent_name, 
    memory=ChatMemory(
        human="My name is Aishwarya", 
        persona="You are a helpful assistant that loves emojis"),
    
    #llm model and endpoint config 
    llm_config= LLMConfig(
        model = 'llama3.2',
        model_endpoint_type ="ollama",
        model_endpoint= 'http://localhost:11434',
        context_window = 8000,  
        ),
    
    # embedding model & endpoint configuration (cannot be changed)
    embedding_config=EmbeddingConfig(
        embedding_endpoint_type="openai",
        embedding_endpoint="https://api.openai.com/v1",
        embedding_model="text-embedding-ada-002",
        embedding_dim=1536,
        embedding_chunk_size=300
    ),
    # system instructions for the agent (defaults to `memgpt_chat`)
    system = gpt_system.get_system_text('memgpt_chat'),
    include_base_tools = True,
    tools = []
    
)

logger.info(f"Created agent with name {agent_state.name} and unique ID {agent_state.id}")    

response = client.send_message(
    agent_id=agent_state.id, 
    message="hello!", 
    role="user" 
)
print(response.messages)

response.usage
print(response.messages)

print(agent_state.system)
agent_state.tools


i = agent_state.tools
logger.info(i)